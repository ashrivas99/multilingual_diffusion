{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5555b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading NotoSans-Regular.ttf\n",
      "Downloading NotoNaskhArabic-Regular.ttf\n",
      "Downloading NotoSansDevanagari-Regular.ttf\n",
      "✅  Wrote 30 rows and 30 PNGs → data\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, random, os, sys, json, urllib.request\n",
    "from pathlib import Path\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "# ─────────────────────── TOP-LEVEL KNOBS ──────────────────────────\n",
    "CSV_FILE        = \"multilingual_data.csv\"   # the full master list\n",
    "OUT_DIR         = Path(\"data\")              # where PNGs + metadata land\n",
    "IMAGE_SIZE      = 128\n",
    "IMAGES_PER_CHAR = 5                         # default full-set duplication\n",
    "\n",
    "# ─── MINI-DATASET SWITCH ──────────────────────────────────────────\n",
    "# If MINI is False the script uses every row in multilingual_data.csv.\n",
    "# If MINI is True it will:\n",
    "#    • keep only the code points listed in MINI_CODES\n",
    "#    • duplicate each of those MINI_COPIES times\n",
    "MINI         = False\n",
    "MINI_CODES   = [\"0041\",\"0641\",\"0915\"]                   # hex Unicode codes for the test\n",
    "MINI_COPIES  = 10\n",
    "\n",
    "# ───────────────────── Font definitions & auto-download ───────────\n",
    "FONTS = {\n",
    "    \"latin\":      \"NotoSans-Regular.ttf\",\n",
    "    \"arabic\":     \"NotoNaskhArabic-Regular.ttf\",\n",
    "    \"devanagari\": \"NotoSansDevanagari-Regular.ttf\",\n",
    "}\n",
    "FONT_URL = {\n",
    "    \"NotoSans-Regular.ttf\":\n",
    "        \"https://github.com/googlefonts/noto-fonts/raw/main/hinted/ttf/NotoSans/NotoSans-Regular.ttf\",\n",
    "    \"NotoNaskhArabic-Regular.ttf\":\n",
    "        \"https://github.com/googlefonts/noto-fonts/raw/main/hinted/ttf/NotoNaskhArabic/NotoNaskhArabic-Regular.ttf\",\n",
    "    \"NotoSansDevanagari-Regular.ttf\":\n",
    "        \"https://github.com/googlefonts/noto-fonts/raw/main/hinted/ttf/NotoSansDevanagari/NotoSansDevanagari-Regular.ttf\",\n",
    "}\n",
    "\n",
    "def ensure_font(ttf):\n",
    "    if Path(ttf).exists():\n",
    "        return\n",
    "    print(f\"Downloading {ttf}\")\n",
    "    urllib.request.urlretrieve(FONT_URL[ttf], ttf)\n",
    "\n",
    "for ttf in FONTS.values():\n",
    "    ensure_font(ttf)\n",
    "\n",
    "# ───────────────────── internal helpers ───────────────────────────\n",
    "def check_row(row):\n",
    "    return int(row.Unicode, 16) == ord(row.Character)\n",
    "\n",
    "def pick_font(ch):\n",
    "    cp = ord(ch)\n",
    "    if   0x0600 <= cp <= 0x06FF: pool = FONTS[\"arabic\"]\n",
    "    elif 0x0900 <= cp <= 0x097F or cp == 0x0950: pool = FONTS[\"devanagari\"]\n",
    "    else: pool = FONTS[\"latin\"]\n",
    "    return ImageFont.truetype(pool, IMAGE_SIZE - 28)\n",
    "\n",
    "def render(ch, font):\n",
    "    img = Image.new(\"L\", (IMAGE_SIZE, IMAGE_SIZE), 255)\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    w, h = draw.textbbox((0, 0), ch, font=font)[2:]\n",
    "    x, y = (IMAGE_SIZE - w)//2, (IMAGE_SIZE - h)//2 - 8\n",
    "    draw.text((x, y), ch, font=font, fill=0)\n",
    "    return img\n",
    "\n",
    "# ───────────────────── main build routine ─────────────────────────\n",
    "def build(csv_file=CSV_FILE,\n",
    "          out_dir=OUT_DIR,\n",
    "          images_per_char=IMAGES_PER_CHAR,\n",
    "          mini=False, mini_codes=None, mini_copies=100):\n",
    "    \n",
    "    df = pd.read_csv(csv_file, dtype=str)\n",
    "    if not df.apply(check_row, axis=1).all():\n",
    "        raise ValueError(\"Unicode ↔ glyph mismatch in CSV\")\n",
    "\n",
    "    if mini:\n",
    "        df = df[df[\"Unicode\"].isin(mini_codes)].reset_index(drop=True)\n",
    "        images_per_char = 1          # we’ll duplicate via DataFrame\n",
    "        df = pd.concat([df]*mini_copies, ignore_index=True)\n",
    "        df[\"dup_id\"] = df.groupby(\"Unicode\").cumcount()\n",
    "        df[\"file_name\"] = df[\"Unicode\"] + \"_\" + df.dup_id.astype(str).str.zfill(3) + \".png\"\n",
    "    else:\n",
    "        df[\"file_name\"] = df[\"Unicode\"].apply(lambda x: f\"{x}.png\")\n",
    "\n",
    "    out_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    # (1) generate PNGs (one per unique file_name)\n",
    "    for row in df.drop_duplicates(\"file_name\").itertuples(index=False):\n",
    "        img = render(row.Character, pick_font(row.Character))\n",
    "        img.save(out_dir / row.file_name)\n",
    "\n",
    "    # (2) metadata\n",
    "    df[[\"file_name\", \"caption\"]].to_json(out_dir / \"metadata.jsonl\",\n",
    "                                         orient=\"records\", lines=True,\n",
    "                                         force_ascii=False)\n",
    "    df.to_csv(out_dir / \"char_dataset.csv\", index=False)\n",
    "    print(f\"✅  Wrote {len(df)} rows and {df.file_name.nunique()} PNGs → {out_dir}\")\n",
    "\n",
    "# ───────────────────── call it! ────────────────────────────────────\n",
    "build(mini=MINI, mini_codes=MINI_CODES, mini_copies=MINI_COPIES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0287971",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
